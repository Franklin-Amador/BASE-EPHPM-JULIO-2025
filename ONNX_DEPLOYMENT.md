# ğŸš€ Deployment ONNX - GuÃ­a Completa

## ğŸ“Š ComparaciÃ³n: PKL vs ONNX

``` text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Componente          â”‚ PKL Version  â”‚ ONNX Version â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ scikit-learn        â”‚ ~150 MB      â”‚ âŒ No need   â”‚
â”‚ onnxruntime         â”‚ âŒ No need   â”‚ ~45 MB       â”‚
â”‚ joblib              â”‚ ~5 MB        â”‚ ~5 MB        â”‚
â”‚ modelo              â”‚ ~50 KB       â”‚ ~50 KB       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL               â”‚ ~155 MB      â”‚ ~50 MB       â”‚
â”‚ ReducciÃ³n           â”‚ -----        â”‚ 68% menor    â”‚
â”‚ Free tier?          â”‚ âŒ NO        â”‚ âœ… SÃ        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ InstalaciÃ³n Local ONNX

### OpciÃ³n 1: Solo dependencias ONNX (recomendado)

```bash
pip install fastapi uvicorn onnxruntime joblib numpy pandas
```

### OpciÃ³n 2: Desde requirements.txt

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Ejecutar API ONNX

### Terminal 1: Iniciar servidor

```bash
cd "BASE EPHPM JULIO 2025"
uvicorn fastapi_app_onnx:app --reload --port 8000
```

### Terminal 2: Probar (PowerShell)

```powershell
# Health check
curl http://localhost:8000/health

# PredicciÃ³n
$body = @{
    ymophg_mean = 8500
    ymophg_median = 7500
    anosest_mean = 6.5
    edad_mean = 35
    totper_mean = 4
    tasa_ocupacion = 0.65
    tasa_pobreza = 0.45
    tasa_nbi = 0.35
} | ConvertTo-Json

curl -X POST http://localhost:8000/predict `
  -H "Content-Type: application/json" `
  -Body $body
```

### Terminal 3: DocumentaciÃ³n

Abre en navegador: **<http://localhost:8000/docs>**

---

## ğŸŒ Deployment a Render.com (Free Tier)

### Archivos necesarios

**1. requirements.txt** (ONNX version)

```txt
fastapi==0.104.1
uvicorn[standard]==0.24.0
onnxruntime==1.16.3
joblib==1.3.2
numpy==1.24.3
pandas==2.1.3
```

### 2. Procfile

``` text
web: uvicorn fastapi_app_onnx:app --host 0.0.0.0 --port $PORT
```

### 3. runtime.txt (opcional)

``` text
python-3.9.18
```

### 4. .gitignore

``` text
venv/
__pycache__/
*.pyc
.DS_Store
.env
```

### Deploy en Render

1. **GitHub**: Push tu cÃ³digo a GitHub

   ``` text

  git init
  git add .
  git commit -m "ONNX deployment ready"
  git branch -M main
  git remote add origin <https://github.com/tu-usuario/tu-repo.git>
  git push -u origin main

   ```

2. **Render.com**:
   - Ir a <https://render.com>
   - Sign up (gratis)
   - New â†’ Web Service
   - Conectar GitHub repo
   - Settings:
     - **Name**: honduras-clustering-api
     - **Runtime**: Python 3
     - **Build Command**: `pip install -r requirements.txt`
     - **Start Command**: `uvicorn fastapi_app_onnx:app --host 0.0.0.0 --port $PORT`

3. **Deploy**:
   - Click "Create Web Service"
   - Espera ~3 minutos
   - Tu API estarÃ¡ en: `https://honduras-clustering-api.onrender.com`

---

## âœ… Test Remoto

```bash
# Health check
curl https://honduras-clustering-api.onrender.com/health

# Docs
https://honduras-clustering-api.onrender.com/docs

# PredicciÃ³n
curl -X POST https://honduras-clustering-api.onrender.com/predict \
  -H "Content-Type: application/json" \
  -d '{
    "ymophg_mean": 8500,
    "ymophg_median": 7500,
    "anosest_mean": 6.5,
    "edad_mean": 35,
    "totper_mean": 4,
    "tasa_ocupacion": 0.65,
    "tasa_pobreza": 0.45,
    "tasa_nbi": 0.35
  }'
```

---

## ğŸ³ Alternativa: Docker

### Dockerfile

```dockerfile
FROM python:3.9-slim

WORKDIR /app

# Copiar archivos
COPY requirements.txt .
COPY fastapi_app_onnx.py .
COPY models/ ./models/

# Instalar dependencias
RUN pip install --no-cache-dir -r requirements.txt

# Comando
CMD ["uvicorn", "fastapi_app_onnx:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Construir y ejecutar

```bash
# Construir
docker build -t clustering-api-onnx .

# Ejecutar localmente
docker run -p 8000:8000 clustering-api-onnx

# Push a Docker Hub
docker tag clustering-api-onnx:latest tu-usuario/clustering-api-onnx:latest
docker push tu-usuario/clustering-api-onnx:latest
```

### Usar en Render (con Docker)

- Conectar repo GitHub
- Render detecta Dockerfile
- Deploy automÃ¡tico

---

## ğŸ“¦ Archivos del Proyecto

``` text
BASE EPHPM JULIO 2025/
â”œâ”€â”€ fastapi_app_onnx.py          # â­ Servidor ONNX (ligero)
â”œâ”€â”€ fastapi_app.py               # Servidor PKL (pesado)
â”œâ”€â”€ clustering_client.py          # Cliente Python
â”œâ”€â”€ requirements.txt              # Dependencias ONNX
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ clustering_model.onnx     # â­ Modelo ONNX (50 KB)
â”‚   â”œâ”€â”€ clustering_pipeline.pkl   # Modelo PKL full
â”‚   â”œâ”€â”€ scaler.pkl                # Normalizador
â”‚   â””â”€â”€ feature_names.txt         # Columnas esperadas
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ gadm41_HND_1.json         # Mapa Honduras
â”‚   â””â”€â”€ ...
â”œâ”€â”€ etl_hogar.ipynb               # Notebook anÃ¡lisis
â””â”€â”€ README.md                     # Este archivo
```

---

## ğŸš¨ Troubleshooting

### Error: "No module named 'onnxruntime'"

```bash
pip install onnxruntime
```

### Error: "ONNX model is corrupted"

Regenerar el ONNX desde notebook:

```python
# En etl_hogar.ipynb, ejecutar celda de conversiÃ³n ONNX
```

### API lenta en free tier

- Render sleep despuÃ©s de 15 min inactividad
- Primera llamada reactiva el servidor (~10 seg)
- Llamadas posteriores son rÃ¡pidas

### Modelo no encuentra "feature_names.txt"

```bash
# Verificar que existe
ls models/

# Si falta, regenerar desde notebook
```

---

## ğŸ¯ Performance Esperado

| MÃ©trica | ONNX | PKL |
| --------- | ------ | ------- |
| Inferencia | ~5 ms | ~10 ms |
| TamaÃ±o | 50 MB | 155 MB |
| Memoria RAM | ~80 MB | ~200 MB |
| Startup | ~2 seg | ~5 seg |
| Free tier? | âœ… SÃ | âŒ NO |

---

## ğŸ“ PrÃ³ximos Pasos

1. âœ… Probar ONNX localmente
2. âœ… Crear cuenta en Render.com
3. âœ… Hacer push a GitHub
4. âœ… Conectar repo en Render
5. âœ… Deploy automÃ¡tico
6. âœ… Compartir URL pÃºblica

---

## ğŸ’¡ Referencias

- [ONNX Runtime Quickstart](https://onnxruntime.ai/docs/get-started/)
- [FastAPI Deployment](https://fastapi.tiangolo.com/deployment/)
- [Render Docs](https://render.com/docs)
- [GitHub Actions CI/CD](https://github.com/features/actions)
